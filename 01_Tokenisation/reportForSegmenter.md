When using the dictionary file, MaxMatch functions well, accurately segmenting the majority of the terms. The only times it should make a mistake are when a word is unknown because the dictionary file is missing it or when many words can be joined to produce a longer term.
Pragmatic segmenter is a rule-based approach for detecting sentence boundaries. Even in situations when the format and domain are unknown, the pragmatic segmenter is designed to function across a wide range of languages. There are no machine-learning techniques used by the pragmatic segmenter. Regular expression is used by the pragmatic segmenter. It introduces errors such occasionally treating citations as complete sentences, adding to the number of lines. Citations, sentence borders, and sentences with some numbers all occur in the incorrect sentences produced by Pragmatic segmenter.
Using an unsupervised learning method to create a model for abbreviations, collocations, and words that start a sentence, the punkt segmenter separates a text into a list of sentences. Prior to use, the punkt segmenter must be trained on a sizable corpus of text in the target language. Regular expressions are used in the Python code for the punkt segmenter. The segmenter correctly classifies every sentence, but, like the pragmatic segmenter, Punkt also treats some citations as sentences in some cases.